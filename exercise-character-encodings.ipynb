{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This notebook is an exercise in the [Data Cleaning](https://www.kaggle.com/learn/data-cleaning) course.  You can reference the tutorial at [this link](https://www.kaggle.com/alexisbcook/character-encodings).**\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"In this exercise, you'll apply what you learned in the **Character encodings** tutorial.\n\n# Setup\n\nThe questions below will give you feedback on your work. Run the following cell to set up the feedback system.","metadata":{}},{"cell_type":"code","source":"from learntools.core import binder\nbinder.bind(globals())\nfrom learntools.data_cleaning.ex4 import *\nprint(\"Setup Complete\")","metadata":{"execution":{"iopub.status.busy":"2023-05-14T05:55:02.148804Z","iopub.execute_input":"2023-05-14T05:55:02.149187Z","iopub.status.idle":"2023-05-14T05:55:02.154782Z","shell.execute_reply.started":"2023-05-14T05:55:02.149159Z","shell.execute_reply":"2023-05-14T05:55:02.153602Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Setup Complete\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Get our environment set up\n\nThe first thing we'll need to do is load in the libraries we'll be using.","metadata":{}},{"cell_type":"code","source":"# modules we'll use\nimport pandas as pd\nimport numpy as np\n\n# helpful character encoding module\nimport charset_normalizer\n\n# set seed for reproducibility\nnp.random.seed(0)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T05:55:06.143276Z","iopub.execute_input":"2023-05-14T05:55:06.143611Z","iopub.status.idle":"2023-05-14T05:55:06.148887Z","shell.execute_reply.started":"2023-05-14T05:55:06.143584Z","shell.execute_reply":"2023-05-14T05:55:06.147584Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# 1) What are encodings?\n\nYou're working with a dataset composed of bytes.  Run the code cell below to print a sample entry.","metadata":{}},{"cell_type":"code","source":"sample_entry = b'\\xa7A\\xa6n'\nprint(sample_entry)\nprint('data type:', type(sample_entry))","metadata":{"execution":{"iopub.status.busy":"2023-05-14T05:55:12.073730Z","iopub.execute_input":"2023-05-14T05:55:12.074715Z","iopub.status.idle":"2023-05-14T05:55:12.080202Z","shell.execute_reply.started":"2023-05-14T05:55:12.074682Z","shell.execute_reply":"2023-05-14T05:55:12.079143Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"b'\\xa7A\\xa6n'\ndata type: <class 'bytes'>\n","output_type":"stream"}]},{"cell_type":"markdown","source":"You notice that it doesn't use the standard UTF-8 encoding. \n\nUse the next code cell to create a variable `new_entry` that changes the encoding from `\"big5-tw\"` to `\"utf-8\"`.  `new_entry` should have the bytes datatype.","metadata":{}},{"cell_type":"code","source":"\nbefore = sample_entry.decode(\"big5-tw\")\nnew_entry = before.encode()\n\n# Check your answer\nq1.check()","metadata":{"execution":{"iopub.status.busy":"2023-05-14T05:56:00.583461Z","iopub.execute_input":"2023-05-14T05:56:00.583793Z","iopub.status.idle":"2023-05-14T05:56:00.592264Z","shell.execute_reply.started":"2023-05-14T05:56:00.583769Z","shell.execute_reply":"2023-05-14T05:56:00.591217Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.3333333333333333, \"interactionType\": 1, \"questionType\": 1, \"questionId\": \"1_EncodingsIntro\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"cell_type":"code","source":"# Lines below will give you a hint or solution code\n#q1.hint()\n#q1.solution()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2) Reading in files with encoding problems\n\nUse the code cell below to read in this file at path `\"../input/fatal-police-shootings-in-the-us/PoliceKillingsUS.csv\"`.  \n\nFigure out what the correct encoding should be and read in the file to a DataFrame `police_killings`.","metadata":{}},{"cell_type":"code","source":"# TODO: Load in the DataFrame correctly.\n# TODO: Load in the DataFrame correctly.\npolice_killings = pd.read_csv(\"../input/fatal-police-shootings-in-the-us/PoliceKillingsUS.csv\", encoding='Windows-1252')\nprint(police_killings)\n\n# Check your answer\nq2.check()","metadata":{"execution":{"iopub.status.busy":"2023-05-14T05:56:29.128164Z","iopub.execute_input":"2023-05-14T05:56:29.128463Z","iopub.status.idle":"2023-05-14T05:56:29.167162Z","shell.execute_reply.started":"2023-05-14T05:56:29.128440Z","shell.execute_reply":"2023-05-14T05:56:29.165909Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"        id                name      date   manner_of_death       armed   age  \\\n0        3          Tim Elliot  02/01/15              shot         gun  53.0   \n1        4    Lewis Lee Lembke  02/01/15              shot         gun  47.0   \n2        5  John Paul Quintero  03/01/15  shot and Tasered     unarmed  23.0   \n3        8     Matthew Hoffman  04/01/15              shot  toy weapon  32.0   \n4        9   Michael Rodriguez  04/01/15              shot    nail gun  39.0   \n...    ...                 ...       ...               ...         ...   ...   \n2530  2822    Rodney E. Jacobs  28/07/17              shot         gun  31.0   \n2531  2813               TK TK  28/07/17              shot     vehicle   NaN   \n2532  2818  Dennis W. Robinson  29/07/17              shot         gun  48.0   \n2533  2817       Isaiah Tucker  31/07/17              shot     vehicle  28.0   \n2534  2815        Dwayne Jeune  31/07/17              shot       knife  32.0   \n\n     gender race           city state  signs_of_mental_illness threat_level  \\\n0         M    A        Shelton    WA                     True       attack   \n1         M    W          Aloha    OR                    False       attack   \n2         M    H        Wichita    KS                    False        other   \n3         M    W  San Francisco    CA                     True       attack   \n4         M    H          Evans    CO                    False       attack   \n...     ...  ...            ...   ...                      ...          ...   \n2530      M  NaN    Kansas City    MO                    False       attack   \n2531      M  NaN    Albuquerque    NM                    False       attack   \n2532      M  NaN          Melba    ID                    False       attack   \n2533      M    B        Oshkosh    WI                    False       attack   \n2534      M    B       Brooklyn    NY                     True       attack   \n\n             flee  body_camera  \n0     Not fleeing        False  \n1     Not fleeing        False  \n2     Not fleeing        False  \n3     Not fleeing        False  \n4     Not fleeing        False  \n...           ...          ...  \n2530  Not fleeing        False  \n2531          Car        False  \n2532          Car        False  \n2533          Car         True  \n2534  Not fleeing        False  \n\n[2535 rows x 14 columns]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.3333333333333333, \"interactionType\": 1, \"questionType\": 1, \"questionId\": \"2_ReadIn\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"cell_type":"markdown","source":"Feel free to use any additional code cells for supplemental work.  To get credit for finishing this question, you'll need to run `q2.check()` and get a result of **Correct**.","metadata":{}},{"cell_type":"code","source":"# (Optional) Use this code cell for any additional work.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lines below will give you a hint or solution code\n#q2.hint()\n#q2.solution()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3) Saving your files with UTF-8 encoding\n\nSave a version of the police killings dataset to CSV with UTF-8 encoding.  Your answer will be marked correct after saving this file.  \n\nNote: When using the `to_csv()` method, supply only the name of the file (e.g., `\"my_file.csv\"`).  This saves the file at the filepath `\"/kaggle/working/my_file.csv\"`.","metadata":{}},{"cell_type":"code","source":"# TODO: Save the police killings dataset to CSV\n____\n\n# Check your answer\nq3.check()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lines below will give you a hint or solution code\n#q3.hint()\n#q3.solution()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# (Optional) More practice\n\nCheck out [this dataset of files in different character encodings](https://www.kaggle.com/rtatman/character-encoding-examples). Can you read in all the files with their original encodings and them save them out as UTF-8 files?\n\nIf you have a file that's in UTF-8 but has just a couple of weird-looking characters in it, you can try out the [ftfy module](https://ftfy.readthedocs.io/en/latest/#) and see if it helps. \n\n# Keep going\n\nIn the final lesson, learn how to [**clean up inconsistent text entries**](https://www.kaggle.com/alexisbcook/inconsistent-data-entry) in your dataset.","metadata":{}},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/data-cleaning/discussion) to chat with other learners.*","metadata":{}}]}